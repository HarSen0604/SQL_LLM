{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ollama mysql-connector-python transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import ollama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Connect to MySQL database and extract schema\n",
    "database = \"VenueScope\"\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Karaikudi-630002\",\n",
    "    database=database\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    TABLE_NAME, \n",
    "    COLUMN_NAME \n",
    "FROM \n",
    "    INFORMATION_SCHEMA.COLUMNS \n",
    "WHERE \n",
    "    TABLE_SCHEMA = '{database}'\n",
    "ORDER BY \n",
    "    TABLE_NAME, ORDINAL_POSITION;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "schema_columns = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process schema to extract table and column names\n",
    "schema_info = {}\n",
    "for table_name, column_name in schema_columns:\n",
    "    if table_name not in schema_info:\n",
    "        schema_info[table_name] = []\n",
    "    schema_info[table_name].append(column_name)\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Helper function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()  # Use mean pooling for sentence embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(user_query):\n",
    "    \"\"\"\n",
    "    Simple keyword extraction to match schema terms.\n",
    "    \"\"\"\n",
    "    keywords = user_query.lower().split()  # Split the query into words\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert table and column names to BERT embeddings\n",
    "def get_schema_embeddings(schema_info):\n",
    "    \"\"\"\n",
    "    Convert schema information (table and column names) into BERT embeddings.\n",
    "    \"\"\"\n",
    "    schema_embeddings = []\n",
    "    table_keys = []\n",
    "    \n",
    "    for table, columns in schema_info.items():\n",
    "        for column in columns:\n",
    "            text = f\"{table} {column}\"\n",
    "            embedding = get_bert_embeddings(text)\n",
    "            schema_embeddings.append(embedding)\n",
    "            table_keys.append(table)\n",
    "    \n",
    "    return schema_embeddings, table_keys\n",
    "\n",
    "schema_embeddings, table_keys = get_schema_embeddings(schema_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueriesFromFile(file_path):\n",
    "    \"\"\"\n",
    "    Read the queries from a file and generate BERT embeddings for each.\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # Open the file and read queries\n",
    "    with open(file_path, 'r') as file:\n",
    "        queries = file.readlines()\n",
    "    \n",
    "    # Generate embeddings for each query\n",
    "    for query in queries:\n",
    "        query = query.strip()  # Remove any leading/trailing whitespace\n",
    "        if query:  # If the query is not empty\n",
    "            queries.append(query)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# Assuming the queries are in 'queries.txt' file\n",
    "file_path = 'queries.txt'\n",
    "queries = getQueriesFromFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process user query and get BERT embeddings\n",
    "user_query = \"List the names of the club heads\"\n",
    "\n",
    "def get_query_embedding(user_query):\n",
    "    \"\"\"\n",
    "    Convert user query into BERT embeddings.\n",
    "    \"\"\"\n",
    "    return get_bert_embeddings(user_query)\n",
    "\n",
    "user_query_embedding = get_query_embedding(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_schemas_v2(user_keywords, schema_info, user_query_embedding, schema_embeddings, table_keys):\n",
    "    \"\"\"\n",
    "    Rank schema tables based on substring matching and BERT embeddings.\n",
    "    Priority is given to exact and partial string matches, with embeddings as a secondary score.\n",
    "    \"\"\"\n",
    "    # Initialize scores\n",
    "    table_scores = {}\n",
    "\n",
    "    # Step 1: Apply string matching to prioritize relevant tables\n",
    "    for table in schema_info:\n",
    "        table_lower = table.lower()\n",
    "        \n",
    "        # Boost for exact substring matches in table name (e.g., \"club_head\")\n",
    "        if 'club_head' in table_lower:\n",
    "            table_scores[table] = table_scores.get(table, 0) + 5\n",
    "        \n",
    "        # Boost for partial matches of user keywords in table name\n",
    "        for keyword in user_keywords:\n",
    "            if keyword in table_lower:\n",
    "                table_scores[table] = table_scores.get(table, 0) + 2\n",
    "\n",
    "    # Step 2: Apply embedding similarity as secondary ranking factor\n",
    "    for i, table in enumerate(table_keys):\n",
    "        similarity_score = cosine_similarity(user_query_embedding, schema_embeddings[i]).flatten()[0]\n",
    "        table_scores[table] = table_scores.get(table, 0) + similarity_score\n",
    "\n",
    "    # Step 3: Sort the tables based on the combined score (higher is better)\n",
    "    ranked_tables = sorted(table_scores.keys(), key=lambda x: table_scores[x], reverse=True)\n",
    "\n",
    "    # Step 4: Remove duplicates, maintaining order\n",
    "    unique_ranked_tables = []\n",
    "    seen_tables = set()\n",
    "    for table in ranked_tables:\n",
    "        if table not in seen_tables:\n",
    "            unique_ranked_tables.append(table)\n",
    "            seen_tables.add(table)\n",
    "\n",
    "    return unique_ranked_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = extract_keywords(user_query)\n",
    "# Step 6: Get query embedding\n",
    "user_query_embedding = get_bert_embeddings(user_query)\n",
    "\n",
    "# Rank schema tables based on query relevance and uniqueness\n",
    "ranked_table_names = rank_schemas_v2(user_keywords, schema_info, user_query_embedding, schema_embeddings, table_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Construct SQL query dynamically based on top-ranked table and columns\n",
    "def construct_sql_query(ranked_table_names, schema_info, user_query, top_n):\n",
    "    \"\"\"\n",
    "    Construct SQL query dynamically using Ollama based on top n-ranked tables and the user's query.\n",
    "    \"\"\"\n",
    "    # Get the top n-ranked tables\n",
    "    top_ranked_tables = ranked_table_names[:top_n]\n",
    "    \n",
    "    # Collect schema information for the top-ranked tables\n",
    "    schema_info_str = \"\"\n",
    "    for table in top_ranked_tables:\n",
    "        columns = schema_info[table]\n",
    "        schema_info_str += f\"Table {table}: Columns ({', '.join(columns)})\\n\"\n",
    "\n",
    "    # Pass the schema info and user query to Ollama\n",
    "    stream = ollama.chat(\n",
    "        model='duckdb-nsql',\n",
    "        messages=[{'role': 'user', 'content': f\"This is the schema: \\n{schema_info_str}\\n{user_query}\"}],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk['message']['content']\n",
    "\n",
    "    return response\n",
    "\n",
    "# top_n = 2  # Set how many top-ranked tables to include\n",
    "# Get the response from Ollama based on the user's query and ranked schema\n",
    "# ollama_query = construct_sql_query(ranked_table_names, schema_info, user_query, top_n)\n",
    "# print(\"Ollama SQL Query:\", ollama_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rank_columns_by_relevance(user_query_embedding, column_names, column_embeddings):\n",
    "    \"\"\"\n",
    "    Compare user query embedding with column embeddings and rank columns based on relevance.\n",
    "    \"\"\"\n",
    "    column_scores = []\n",
    "    user_query_embedding = user_query_embedding.reshape(1, -1)  # Reshape user query embedding to 2D\n",
    "\n",
    "    for column, embedding in zip(column_names, column_embeddings):\n",
    "        embedding = embedding.reshape(1, -1)  # Reshape column embedding to 2D\n",
    "        # Compute similarity between the user query and each column embedding (cosine similarity)\n",
    "        similarity_score = cosine_similarity(user_query_embedding, embedding)[0][0]  # Extract scalar\n",
    "        column_scores.append((column, similarity_score))\n",
    "\n",
    "    # Sort columns by relevance (higher similarity score first)\n",
    "    column_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return column_scores\n",
    "\n",
    "\n",
    "\n",
    "def construct_and_execute_query(cursor, ranked_table_names, schema_info, user_query, top_n, max_attempts=5):\n",
    "    \"\"\"\n",
    "    retry_construct_and_execute_query_with_column_reranking\n",
    "    For each top_n ranked table, rank its columns by relevance to the user query,\n",
    "    re-rank tables based on the relevance of columns, and generate SQL query if relevant.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    ollama_query = \"\"\n",
    "    user_query_embedding = get_bert_embeddings(user_query)  # Embed the user's query\n",
    "\n",
    "    while not success and attempt < max_attempts:\n",
    "        try:\n",
    "            # Increment attempt count\n",
    "            attempt += 1\n",
    "            print(f\"Attempt {attempt} to generate and execute the query...\")\n",
    "\n",
    "            # Iterate over top-ranked tables to find the most relevant column match\n",
    "            for table_name in ranked_table_names[:top_n]:\n",
    "                column_names = schema_info[table_name]  # Get columns for the table\n",
    "                column_embeddings = get_bert_embeddings(column_names)  # Embed the column names\n",
    "\n",
    "                # Rank columns based on their relevance to the user's query\n",
    "                ranked_columns = rank_columns_by_relevance(user_query_embedding, column_names, column_embeddings)\n",
    "                print(f\"Ranked columns for table {table_name}: {ranked_columns}\")\n",
    "\n",
    "                # Check if the top-ranked column has sufficient relevance\n",
    "                top_column, relevance_score = ranked_columns[0]\n",
    "                print(f\"Top column: {top_column}, Relevance score: {relevance_score}\")\n",
    "\n",
    "                if relevance_score > 0.5:  # Threshold for relevance (can be adjusted)\n",
    "                    print(f\"Proceeding with table {table_name} and top column {top_column}\")\n",
    "\n",
    "                    # Generate SQL query using Ollama with the relevant table and columns\n",
    "                    ollama_query = construct_sql_query([table_name], schema_info, user_query, top_n=1)\n",
    "                    print(\"Generated Query from Ollama:\", ollama_query)\n",
    "\n",
    "                    # Try executing the query\n",
    "                    cursor.execute(ollama_query)\n",
    "                    results = cursor.fetchall()\n",
    "                    success = True  # Mark success if query executes successfully\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Relevance score too low for table {table_name}. Trying the next table...\")\n",
    "\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Query execution failed with error: {err}\")\n",
    "            print(\"Re-ranking columns and trying the next table...\")\n",
    "\n",
    "    # If successful, return the results\n",
    "    if success:\n",
    "        print(\"Query executed successfully!\")\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"Failed after {max_attempts} attempts.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top-ranked tables to pass to Ollama\n",
    "top_n = 4\n",
    "\n",
    "# Call the retry function with column ranking and re-ranking based on user query relevance\n",
    "results = construct_and_execute_query(cursor, ranked_table_names, schema_info, user_query, top_n)\n",
    "\n",
    "# Print the results if successful\n",
    "if results:\n",
    "    for row in results:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close cursor and database connection\n",
    "cursor.close()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
