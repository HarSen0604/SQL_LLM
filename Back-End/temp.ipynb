{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ollama mysql-connector-python transformers torch nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import ollama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the stopwords if you haven't done so\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Connect to MySQL database and extract schema\n",
    "database = \"VenueScope\"\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Karaikudi-630002\",\n",
    "    database=database\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    TABLE_NAME, \n",
    "    COLUMN_NAME \n",
    "FROM \n",
    "    INFORMATION_SCHEMA.COLUMNS \n",
    "WHERE \n",
    "    TABLE_SCHEMA = '{database}'\n",
    "ORDER BY \n",
    "    TABLE_NAME, ORDINAL_POSITION;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "schema_columns = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process schema to extract table and column names\n",
    "schema_info = {}\n",
    "for table_name, column_name in schema_columns:\n",
    "    if table_name not in schema_info:\n",
    "        schema_info[table_name] = []\n",
    "    schema_info[table_name].append(column_name)\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Helper function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()  # Use mean pooling for sentence embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(query):\n",
    "    \"\"\"\n",
    "    Extract keywords from the query while removing stop words.\n",
    "    \"\"\"\n",
    "    words = query.lower().split()  # Simple tokenization\n",
    "    keywords = [word for word in words if word not in stop_words]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert table and column names to BERT embeddings\n",
    "def get_schema_embeddings(schema_info):\n",
    "    \"\"\"\n",
    "    Convert schema information (table and column names) into BERT embeddings.\n",
    "    \"\"\"\n",
    "    schema_embeddings = []\n",
    "    table_keys = []\n",
    "    \n",
    "    for table, columns in schema_info.items():\n",
    "        for column in columns:\n",
    "            text = f\"{table} {column}\"\n",
    "            embedding = get_bert_embeddings(text)\n",
    "            schema_embeddings.append(embedding)\n",
    "            table_keys.append(table)\n",
    "    \n",
    "    return schema_embeddings, table_keys\n",
    "\n",
    "schema_embeddings, table_keys = get_schema_embeddings(schema_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(user_query):\n",
    "    \"\"\"\n",
    "    Convert user query into BERT embeddings.\n",
    "    \"\"\"\n",
    "    return get_bert_embeddings(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_schemas_v2(user_keywords, schema_info, user_query_embedding, schema_embeddings, table_keys):\n",
    "    \"\"\"\n",
    "    Rank schema tables based on substring matching and BERT embeddings.\n",
    "    Priority is given to matches of user keywords, with embeddings as a secondary score.\n",
    "    \"\"\"\n",
    "    # Initialize scores\n",
    "    table_scores = {}\n",
    "\n",
    "    # Extract relevant keywords from the user query\n",
    "    relevant_keywords = set(keyword.lower() for keyword in user_keywords)\n",
    "\n",
    "    # Step 1: Apply string matching to prioritize relevant tables\n",
    "    for table in schema_info:\n",
    "        columns = schema_info[table]\n",
    "        table_lower = table.lower()\n",
    "\n",
    "        # Boost for matches of relevant keywords in table name\n",
    "        for keyword in relevant_keywords:\n",
    "            if keyword in table_lower:\n",
    "                table_scores[table] = table_scores.get(table, 0) + 2\n",
    "        \n",
    "        # Boost for matches of relevant keywords in column names\n",
    "        for column in columns:\n",
    "            for keyword in relevant_keywords:\n",
    "                if keyword in column.lower():\n",
    "                    table_scores[table] = table_scores.get(table, 0) + 2  # Adjust boost as needed\n",
    "\n",
    "    # Step 2: Apply embedding similarity as secondary ranking factor\n",
    "    for i, table in enumerate(table_keys):\n",
    "        similarity_score = cosine_similarity(user_query_embedding, schema_embeddings[i]).flatten()[0]\n",
    "        table_scores[table] = table_scores.get(table, 0) + similarity_score\n",
    "\n",
    "    # Step 3: Sort the tables based on the combined score (higher is better)\n",
    "    ranked_tables = sorted(table_scores.keys(), key=lambda x: table_scores[x], reverse=True)\n",
    "\n",
    "    # Step 4: Remove duplicates, maintaining order\n",
    "    unique_ranked_tables = []\n",
    "    seen_tables = set()\n",
    "    for table in ranked_tables:\n",
    "        if table not in seen_tables:\n",
    "            unique_ranked_tables.append(table)\n",
    "            seen_tables.add(table)\n",
    "\n",
    "    return unique_ranked_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Construct SQL query dynamically based on top-ranked table and columns\n",
    "def construct_sql_query(ranked_table_names, schema_info, user_query, top_n):\n",
    "    \"\"\"\n",
    "    Construct SQL query dynamically using Ollama based on top n-ranked tables and the user's query.\n",
    "    \"\"\"\n",
    "    # Get the top n-ranked tables\n",
    "    top_ranked_tables = ranked_table_names[:top_n]\n",
    "    \n",
    "    # Collect schema information for the top-ranked tables\n",
    "    schema_info_str = \"\"\n",
    "    for table in top_ranked_tables:\n",
    "        columns = schema_info[table]\n",
    "        schema_info_str += f\"Table {table}: Columns ({', '.join(columns)})\\n\"\n",
    "\n",
    "    # Pass the schema info and user query to Ollama\n",
    "    stream = ollama.chat(\n",
    "        model='duckdb-nsql',\n",
    "        messages=[{'role': 'user', 'content': f\"This is the schema: \\n{schema_info_str}\\n{user_query}\"}],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk['message']['content']\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# top_n = 2  # Set how many top-ranked tables to include\n",
    "# Get the response from Ollama based on the user's query and ranked schema\n",
    "# ollama_query = construct_sql_query(ranked_table_names, schema_info, user_query, top_n)\n",
    "# print(\"Ollama SQL Query:\", ollama_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Modify ranking to consider foreign keys and relationships\n",
    "def get_foreign_key_relations(cursor, schema_info, database):\n",
    "    \"\"\"\n",
    "    Extract foreign key relationships from the INFORMATION_SCHEMA for the given database.\n",
    "    Returns a dictionary mapping tables to their related tables via foreign keys.\n",
    "    \"\"\"\n",
    "    foreign_key_query = f\"\"\"\n",
    "    SELECT \n",
    "        TABLE_NAME, \n",
    "        COLUMN_NAME, \n",
    "        REFERENCED_TABLE_NAME, \n",
    "        REFERENCED_COLUMN_NAME\n",
    "    FROM \n",
    "        INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "    WHERE \n",
    "        TABLE_SCHEMA = '{database}' \n",
    "        AND REFERENCED_TABLE_NAME IS NOT NULL;\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(foreign_key_query)\n",
    "    foreign_keys = cursor.fetchall()\n",
    "    \n",
    "    fk_relations = {}\n",
    "    for table, column, ref_table, ref_column in foreign_keys:\n",
    "        if table not in fk_relations:\n",
    "            fk_relations[table] = []\n",
    "        fk_relations[table].append((column, ref_table, ref_column))\n",
    "    \n",
    "    return fk_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rank_columns_by_relevance(user_query_embedding, column_names, column_embeddings):\n",
    "    \"\"\"\n",
    "    Compare user query embedding with column embeddings and rank columns based on relevance.\n",
    "    \"\"\"\n",
    "    column_scores = []\n",
    "    user_query_embedding = user_query_embedding.reshape(1, -1)  # Reshape user query embedding to 2D\n",
    "\n",
    "    for column, embedding in zip(column_names, column_embeddings):\n",
    "        embedding = embedding.reshape(1, -1)  # Reshape column embedding to 2D\n",
    "        # Compute similarity between the user query and each column embedding (cosine similarity)\n",
    "        similarity_score = cosine_similarity(user_query_embedding, embedding)[0][0]  # Extract scalar\n",
    "        column_scores.append((column, similarity_score))\n",
    "\n",
    "    # Sort columns by relevance (higher similarity score first)\n",
    "    column_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return column_scores\n",
    "\n",
    "\n",
    "\n",
    "def construct_and_execute_query(cursor, ranked_table_names, schema_info, user_query, top_n, max_attempts=5):\n",
    "    \"\"\"\n",
    "    retry_construct_and_execute_query_with_column_reranking\n",
    "    For each top_n ranked table, rank its columns by relevance to the user query,\n",
    "    re-rank tables based on the relevance of columns, and generate SQL query if relevant.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    ollama_query = \"\"\n",
    "    user_query_embedding = get_bert_embeddings(user_query)  # Embed the user's query\n",
    "\n",
    "    while not success and attempt < max_attempts:\n",
    "        try:\n",
    "            # Increment attempt count\n",
    "            attempt += 1\n",
    "            print(f\"Attempt {attempt} to generate and execute the query...\")\n",
    "\n",
    "            # Iterate over top-ranked tables to find the most relevant column match\n",
    "            for table_name in ranked_table_names[:top_n]:\n",
    "                column_names = schema_info[table_name]  # Get columns for the table\n",
    "                column_embeddings = get_bert_embeddings(column_names)  # Embed the column names\n",
    "\n",
    "                # Rank columns based on their relevance to the user's query\n",
    "                ranked_columns = rank_columns_by_relevance(user_query_embedding, column_names, column_embeddings)\n",
    "                print(f\"Ranked columns for table {table_name}: {ranked_columns}\")\n",
    "\n",
    "                # Check if the top-ranked column has sufficient relevance\n",
    "                top_column, relevance_score = ranked_columns[0]\n",
    "                print(f\"Top column: {top_column}, Relevance score: {relevance_score}\")\n",
    "\n",
    "                if relevance_score > 0.5:  # Threshold for relevance (can be adjusted)\n",
    "                    print(f\"Proceeding with table {table_name} and top column {top_column}\")\n",
    "\n",
    "                    # Generate SQL query using Ollama with the relevant table and columns\n",
    "                    ollama_query = construct_sql_query([table_name], schema_info, user_query, top_n=1)\n",
    "                    print(\"Generated Query from Ollama:\", ollama_query)\n",
    "\n",
    "                    # Try executing the query\n",
    "                    cursor.execute(ollama_query)\n",
    "                    results = cursor.fetchall()\n",
    "                    success = True  # Mark success if query executes successfully\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Relevance score too low for table {table_name}. Trying the next table...\")\n",
    "\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Query execution failed with error: {err}\")\n",
    "            print(\"Re-ranking columns and trying the next table...\")\n",
    "\n",
    "    # If successful, return the results\n",
    "    if success:\n",
    "        print(\"Query executed successfully!\")\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"Failed after {max_attempts} attempts.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foreign_keys(cursor, schema_info):\n",
    "    \"\"\"\n",
    "    Extract foreign key relationships for the tables in schema_info.\n",
    "    \"\"\"\n",
    "    foreign_keys = {}\n",
    "    for table in schema_info.keys():\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT \n",
    "                COLUMN_NAME, \n",
    "                REFERENCED_TABLE_NAME, \n",
    "                REFERENCED_COLUMN_NAME\n",
    "            FROM \n",
    "                INFORMATION_SCHEMA.KEY_COLUMN_USAGE\n",
    "            WHERE \n",
    "                TABLE_NAME = '{table}' AND \n",
    "                TABLE_SCHEMA = 'your_database_name' AND \n",
    "                REFERENCED_TABLE_NAME IS NOT NULL;\n",
    "        \"\"\")\n",
    "        foreign_keys[table] = cursor.fetchall()\n",
    "    return foreign_keys\n",
    "\n",
    "\n",
    "def construct_sql_query_for_ollama(top_tables, schema_info, user_query):\n",
    "    \"\"\"\n",
    "    Construct SQL query using schema information for the top tables.\n",
    "    \"\"\"\n",
    "    schema_info_str = \"\"\n",
    "    for table in top_tables:\n",
    "        columns = schema_info[table]\n",
    "        schema_info_str += f\"Table {table}: Columns ({', '.join(columns)})\\n\"\n",
    "\n",
    "    # Prepare the final query for Ollama\n",
    "    query_for_ollama = f\"{schema_info_str}\\n{user_query}\"\n",
    "    return query_for_ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueriesFromFile(file_path):\n",
    "    \"\"\"\n",
    "    Read the queries from a file and generate BERT embeddings for each.\n",
    "    \"\"\"\n",
    "    print(\"Reading file...\")\n",
    "    queries = []\n",
    "    \n",
    "    # Open the file and read queries\n",
    "    with open(file_path, 'r') as file:\n",
    "        queries = file.readlines()\n",
    "    \n",
    "    print(f\"Total lines read: {len(queries)}\")\n",
    "    \n",
    "    # Generate embeddings for each query\n",
    "    for i in range (len(queries)):\n",
    "        queries[i] = queries[i].strip()  # Remove any leading/trailing whitespace\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# Assuming the queries are in 'queries.txt' file\n",
    "file_path = '../Testing/queries.txt'\n",
    "queries = getQueriesFromFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of attempts for executing the query\n",
    "max_attempts = 5\n",
    "top_n = 3  # Adjust the number of top tables as needed\n",
    "\n",
    "for query in queries:\n",
    "    user_keywords = extract_keywords(query)\n",
    "    user_query_embedding = get_bert_embeddings(query)\n",
    "\n",
    "    # Rank schema tables based on query relevance and uniqueness\n",
    "    ranked_table_names = rank_schemas_v2(user_keywords, schema_info, user_query_embedding, schema_embeddings, table_keys)\n",
    "    print(ranked_table_names)\n",
    "\n",
    "    top_tables_after_re_ranking = ranked_table_names[:top_n]  # Get the top tables after re-ranking\n",
    "\n",
    "    # Retry logic for generating and executing the query\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    while not success and attempt < max_attempts:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            print(f\"Attempt {attempt} to generate and execute the query...\")\n",
    "\n",
    "            # Construct the query for Ollama\n",
    "            ollama_query = construct_sql_query_for_ollama(top_tables_after_re_ranking, schema_info, query)\n",
    "\n",
    "            # Pass this to Ollama for query generation\n",
    "            stream = ollama.chat(\n",
    "                model='duckdb-nsql',\n",
    "                messages=[{'role': 'user', 'content': ollama_query}],\n",
    "                stream=True,\n",
    "            )\n",
    "\n",
    "            response = \"\"\n",
    "            for chunk in stream:\n",
    "                response += chunk['message']['content']\n",
    "\n",
    "            # Execute the generated SQL query\n",
    "            cursor.execute(response)\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "            # If successful, print results and mark success\n",
    "            success = True\n",
    "            print(query)\n",
    "            print(response, results)\n",
    "\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Query execution failed with error: {err}\")\n",
    "            print(\"Retrying...\")  # Log the retry\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            print(\"Retrying...\")  # Log the retry\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed to execute query after {max_attempts} attempts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close cursor and database connection\n",
    "cursor.close()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
